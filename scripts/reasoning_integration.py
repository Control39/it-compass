#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Reasoning-–º–æ–¥–µ–ª–∏ —Å IT Compass.
–ü–æ–∑–≤–æ–ª—è–µ—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–º–µ—Ç–∫–∏/–¥–∏–∞–ª–æ–≥–∏ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª—è—Ç—å —Å –º–∞—Ä–∫–µ—Ä–∞–º–∏.
"""
import json
import os
import sys
import requests
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime

# Add the project root to the path to allow imports
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.core.tracker import CareerTracker
from src.utils.portfolio_gen import PortfolioGenerator


class ReasoningIntegrator:
    def __init__(self, tracker: CareerTracker):
        self.tracker = tracker
        self.reasoning_api_url = os.getenv("REASONING_API_URL", "https://api.openai.com/v1/chat/completions")
        self.reasoning_api_key = os.getenv("REASONING_API_KEY")
        self.reasoning_model = os.getenv("REASONING_MODEL", "gpt-4")
        
    def analyze_notes_with_reasoning(self, notes_content: str) -> List[Dict]:
        """
        –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∑–∞–º–µ—Ç–æ–∫ –≤ reasoning-–º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤.
        """
        if not self.reasoning_api_key:
            print("‚ö†Ô∏è REASONING_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–º—É–ª—è—Ü–∏—é.")
            return self._simulate_reasoning_analysis(notes_content)
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è reasoning-–º–æ–¥–µ–ª–∏
        markers_text = self._get_all_markers_text()
        
        prompt = f"""
        –¢—ã - –∞–Ω–∞–ª–∏—Ç–∏–∫, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –æ—Ü–µ–Ω–∫–µ IT-–∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π.
        –ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω—ã —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Ç–µ–∫—Å—Ç–∞ (–∑–∞–º–µ—Ç–∫–∏/–¥–∏–∞–ª–æ–≥–∏), –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –∏–∑ –∞—Ä—Ö–∏–≤–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        
        –¢–≤–æ—è –∑–∞–¥–∞—á–∞:
        1. –í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç–∞.
        2. –ù–∞–π—Ç–∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π, —Ä–µ—à–µ–Ω–∏–π, –∞–Ω–∞–ª–∏–∑–∞, –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è, –Ω–∞–ø–∏—Å–∞–Ω–∏—è –∫–æ–¥–∞, –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π –∏ —Ç.–¥.
        3. –°–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è/–∑–Ω–∞–Ω–∏—è —Å –º–∞—Ä–∫–µ—Ä–∞–º–∏ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π IT Compass.
        4. –í—ã–≤–µ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON: —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤, –≥–¥–µ –∫–∞–∂–¥—ã–π –æ–±—ä–µ–∫—Ç –∏–º–µ–µ—Ç —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É:
           - "matched_marker_id": "ID –º–∞—Ä–∫–µ—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'python_1_1')",
           - "context_snippet": "–¢–æ—á–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç–∞, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –æ—Å–Ω–æ–≤–∞–Ω–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ",
           - "confidence": "–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ (–Ω–∏–∑–∫–∞—è/—Å—Ä–µ–¥–Ω—è—è/–≤—ã—Å–æ–∫–∞—è)",
           - "comment": "–ö—Ä–∞—Ç–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π, –æ–±—ä—è—Å–Ω—è—é—â–∏–π, –ø–æ—á–µ–º—É —ç—Ç–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –±—ã–ª–æ —Å–¥–µ–ª–∞–Ω–æ."

        –í–ê–ñ–ù–û: –í—ã–≤–æ–¥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –¥–æ –∏–ª–∏ –ø–æ—Å–ª–µ. –ï—Å–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ [].

        –°–ø–∏—Å–æ–∫ –º–∞—Ä–∫–µ—Ä–æ–≤ IT Compass:
        {markers_text}

        –ó–∞–º–µ—Ç–∫–∏/–¥–∏–∞–ª–æ–≥–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
        {notes_content}
        """
        
        payload = {
            "model": self.reasoning_model,
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.1,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –±–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞
        }
        
        headers = {
            "Authorization": f"Bearer {self.reasoning_api_key}",
            "Content-Type": "application/json"
        }
        
        try:
            response = requests.post(self.reasoning_api_url, json=payload, headers=headers)
            response.raise_for_status()
            data = response.json()
            reasoning_output_text = data['choices'][0]['message']['content'].strip()
            
            # –ü–æ–ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
            start_idx = reasoning_output_text.find('[')
            end_idx = reasoning_output_text.rfind(']') + 1
            if start_idx != -1 and end_idx != 0:
                json_str = reasoning_output_text[start_idx:end_idx]
                try:
                    reasoning_output_json = json.loads(json_str)
                    return reasoning_output_json
                except json.JSONDecodeError as e:
                    print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ Reasoning API: {e}")
                    print("–û—Ç–≤–µ—Ç API:")
                    print(reasoning_output_text)
                    return []
            else:
                print("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ JSON –≤ –æ—Ç–≤–µ—Ç–µ Reasoning API.")
                print("–û—Ç–≤–µ—Ç API:")
                print(reasoning_output_text)
                return []
                
        except requests.exceptions.RequestException as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ Reasoning API: {e}")
            return []
    
    def _simulate_reasoning_analysis(self, notes_content: str) -> List[Dict]:
        """
        –°–∏–º—É–ª—è—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ reasoning-–º–æ–¥–µ–ª—å—é –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏.
        """
        print("–°–∏–º—É–ª—è—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞...")
        
        # –ù–∞–π–¥–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –≤ —Ç–µ–∫—Å—Ç–µ
        found_markers = []
        
        # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        if "python" in notes_content.lower() or "script" in notes_content.lower():
            for skill_data in self.tracker.markers.values():
                for level_markers in skill_data.levels.values():
                    for marker in level_markers:
                        if "python" in marker.marker.lower() or "script" in marker.marker.lower():
                            found_markers.append({
                                "matched_marker_id": marker.id,
                                "context_snippet": notes_content[:200] + "...",
                                "confidence": "—Å—Ä–µ–¥–Ω—è—è",
                                "comment": "–ù–∞–π–¥–µ–Ω–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ Python/—Å–∫—Ä–∏–ø—Ç–∞ –≤ –∑–∞–º–µ—Ç–∫–∞—Ö"
                            })
                            break  # –î–æ–±–∞–≤–∏–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π –º–∞—Ä–∫–µ—Ä –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        
        return found_markers
    
    def _get_all_markers_text(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤—Å–µ—Ö –º–∞—Ä–∫–µ—Ä–æ–≤ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞."""
        markers_text = []
        for skill_name, skill_data in self.tracker.markers.items():
            markers_text.append(f"\n{skill_name}:")
            for level, level_markers in skill_data.levels.items():
                for marker in level_markers:
                    markers_text.append(f"  - {marker.id}: {marker.marker}")
        
        return "\n".join(markers_text)
    
    def process_notes_file(self, file_path: str) -> List[Dict]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª —Å –∑–∞–º–µ—Ç–∫–∞–º–∏."""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            return self.analyze_notes_with_reasoning(content)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            return []
    
    def process_notes_directory(self, directory_path: str) -> List[Dict]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –∑–∞–º–µ—Ç–∫–∞–º–∏."""
        all_matches = []
        
        directory = Path(directory_path)
        if not directory.exists():
            print(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {directory_path} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            return []
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        for file_path in directory.rglob("*"):
            if file_path.is_file() and file_path.suffix.lower() in ['.txt', '.md', '.json', '.py', '.js', '.html', '.css']:
                print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {file_path}")
                matches = self.process_notes_file(str(file_path))
                all_matches.extend(matches)
        
        return all_matches
    
    def apply_matches_to_tracker(self, matches: List[Dict]) -> Dict:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –∫ —Ç—Ä–µ–∫–µ—Ä—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É."""
        results = {
            "applied": 0,
            "skipped": 0,
            "errors": 0
        }
        
        for match in matches:
            marker_id = match.get("matched_marker_id")
            if not marker_id:
                results["errors"] += 1
                continue
            
            # –ü—Ä–æ–≤–µ—Ä–∏–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –º–∞—Ä–∫–µ—Ä
            if self._marker_exists(marker_id):
                # –ü—Ä–æ–≤–µ—Ä–∏–º, –Ω–µ –æ—Ç–º–µ—á–µ–Ω –ª–∏ –æ–Ω —É–∂–µ
                if marker_id not in self.tracker.progress["completed_markers"]:
                    success = self.tracker.mark_completed(marker_id)
                    if success:
                        results["applied"] += 1
                        print(f"‚úÖ –ú–∞—Ä–∫–µ—Ä {marker_id} –æ—Ç–º–µ—á–µ–Ω –∫–∞–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–π")
                    else:
                        results["errors"] += 1
                else:
                    results["skipped"] += 1
            else:
                results["errors"] += 1
        
        return results
    
    def _marker_exists(self, marker_id: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –º–∞—Ä–∫–µ—Ä –≤ —Å–∏—Å—Ç–µ–º–µ."""
        for skill_data in self.tracker.markers.values():
            for level_markers in skill_data.levels.values():
                for marker in level_markers:
                    if marker.id == marker_id:
                        return True
        return False


def main():
    print("üöÄ –ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Reasoning-–º–æ–¥–µ–ª–∏ —Å IT Compass")
    print("=" * 60)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–∫–µ—Ä–∞
    tracker = CareerTracker()
    integrator = ReasoningIntegrator(tracker)
    
    # –ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å
    print("\nüìä –¢–ï–ö–£–©–ò–ô –ü–†–û–ì–†–ï–°–°:")
    tracker.show_progress()
    
    print("\nüîç –í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –∑–∞–º–µ—Ç–∫–∞–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    print("–ü—Ä–∏–º–µ—Ä: /path/to/notes/directory –∏–ª–∏ /path/to/note.txt")
    print("–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–∏–º–µ—Ä–∞ –≤–≤–µ–¥–∏—Ç–µ 'demo':")
    
    user_input = input("–ü—É—Ç—å: ").strip()
    
    if user_input.lower() == 'demo':
        # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –ø—Ä–∏–º–µ—Ä
        demo_content = """
        –°–µ–≥–æ–¥–Ω—è —è –Ω–∞–ø–∏—Å–∞–ª —Å–∫—Ä–∏–ø—Ç –Ω–∞ Python –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Ä—É—Ç–∏–Ω–Ω–æ–π –∑–∞–¥–∞—á–∏.
        –¢–∞–∫–∂–µ —Ä–µ—à–∏–ª –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–¥–∞—á –Ω–∞ Codewars –∏ —Å–æ–∑–¥–∞–ª –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Flask.
        –†–∞–±–æ—Ç–∞–ª —Å Docker –¥–ª—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.
        """
        print("\nüìù –ê–Ω–∞–ª–∏–∑ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
        matches = integrator.analyze_notes_with_reasoning(demo_content)
    elif Path(user_input).is_file():
        print(f"\nüìù –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ {user_input}...")
        matches = integrator.process_notes_file(user_input)
    elif Path(user_input).is_dir():
        print(f"\nüìù –ê–Ω–∞–ª–∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {user_input}...")
        matches = integrator.process_notes_directory(user_input)
    else:
        print("‚ùå –£–∫–∞–∑–∞–Ω–Ω—ã–π –ø—É—Ç—å –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        return
    
    print(f"\nüéØ –ù–∞–π–¥–µ–Ω–æ {len(matches)} –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π")
    
    if matches:
        print("\nüìã –ù–ê–ô–î–ï–ù–ù–´–ï –°–û–í–ü–ê–î–ï–ù–ò–Ø:")
        for i, match in enumerate(matches, 1):
            print(f"{i}. –ú–∞—Ä–∫–µ—Ä: {match.get('matched_marker_id', 'N/A')}")
            print(f"   –ö–æ–Ω—Ç–µ–∫—Å—Ç: {match.get('context_snippet', 'N/A')[:100]}...")
            print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {match.get('confidence', 'N/A')}")
            print(f"   –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: {match.get('comment', 'N/A')}")
            print()
        
        print("‚úÖ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –∫ —Ç—Ä–µ–∫–µ—Ä—É...")
        results = integrator.apply_matches_to_tracker(matches)
        
        print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–†–ò–ú–ï–ù–ï–ù–ò–Ø:")
        print(f"  - –ü—Ä–∏–º–µ–Ω–µ–Ω–æ: {results['applied']}")
        print(f"  - –ü—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ –æ—Ç–º–µ—á–µ–Ω—ã): {results['skipped']}")
        print(f"  - –û—à–∏–±–æ–∫: {results['errors']}")
    
    # –ü–æ–∫–∞–∑–∞—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å
    print("\nüìä –û–ë–ù–û–í–õ–ï–ù–ù–´–ô –ü–†–û–ì–†–ï–°–°:")
    tracker.show_progress()
    
    # –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤–æ–µ –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ
    print("\nüìÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ...")
    generator = PortfolioGenerator()
    success = generator.generate_portfolio()
    
    if success:
        print("‚úÖ –ü–æ—Ä—Ç—Ñ–æ–ª–∏–æ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–æ!")
    else:
        print("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ")


if __name__ == "__main__":
    main()